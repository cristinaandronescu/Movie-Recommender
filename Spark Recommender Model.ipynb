{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to setup data path\n",
    "import urllib\n",
    "ACCESS_KEY = \"AKIAJLS4T44ALM4KDLKA\"\n",
    "SECRET_KEY = \"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\"\n",
    "ENCODED_SECRET_KEY = urllib.quote(SECRET_KEY, \"\")\n",
    "AWS_BUCKET_NAME = \"moviecapstone\"\n",
    "MOUNT_NAME = \"mys3\"\n",
    "dbutils.fs.mount(\"s3n://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, AWS_BUCKET_NAME), \"/mnt/%s\" % MOUNT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"/mnt/mys3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sc.textFile(\"/mnt/mys3/movs.csv\").take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies = sc.textFile(\"/mnt/mys3/movs.csv\")\n",
    "movies_header = movies.take(1)[0]\n",
    "movies.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings = sc.textFile(\"/mnt/mys3/rats.csv\")\n",
    "ratings_header = ratings.take(1)[0]\n",
    "ratings_header.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_data = ratings.filter(lambda x: x!=ratings_header).map(lambda x: x.split(\",\")).map(lambda tokens: (tokens[1],tokens[2], tokens[3])).cache()\n",
    "ratings_data.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, testing = ratings_data.randomSplit([8,2], seed = 0L) \n",
    "#traning.count() # 15986331\n",
    "#testing.count() # 3997693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_train, training_validation, training_test = training.randomSplit([6,2,2], seed = 0L)\n",
    "validation_for_predict = training_validation.map(lambda x: (x[0], x[1]))\n",
    "test_for_predict = training_test.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_train.count() # 9590161\n",
    "training_validation.count() # 3198763\n",
    "training_test.count() #3197407"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0L)\n",
    "#validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
    "#test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_train.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import ALS\n",
    "import math\n",
    "\n",
    "\n",
    "seed = 50L\n",
    "iterations = 50\n",
    "reg_parameter = 0.05\n",
    "ranks = [13, 20, 30]\n",
    "errors = [0, 0, 0]\n",
    "err = 0\n",
    "\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "best_iteration = -1\n",
    "\n",
    "\n",
    "#for rp in reg_parameter:\n",
    "for rank in ranks:\n",
    "    model = ALS.train(training_train, rank, seed=seed, iterations=iterations,\n",
    "                          lambda_=reg_parameter)\n",
    "    predictions = model.predictAll(validation_for_predict).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    rates_and_preds = training_validation.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    errors[err] = error\n",
    "    err += 1\n",
    "    print 'For rank %s the RMSE is %s' % (rank, error)\n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = rank\n",
    "\n",
    "print 'The best model was trained with rank %s' % best_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates_and_preds.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model on the training subsection of the training data\n",
    "model = ALS.train(training_train, best_rank, seed=seed, iterations=iterations,\n",
    "                      lambda_=reg_parameter)\n",
    "predictions = model.predictAll(test_for_predict).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds = training_test.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print 'For testing data the RMSE is %s' % (error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build model on entire training data set\n",
    "tr_model = ALS.train(training, best_rank, seed=seed, iterations=iterations, lambda_=reg_parameter)\n",
    "tr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_for_predict_tr = testing.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "predictions_tr = tr_model.predictAll(test_for_predict_tr).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "rates_and_preds_tr = testing.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions_tr)\n",
    "error_tr = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "print 'For testing data the RMSE is %s' % (error_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from operator import add\n",
    "numTrTest = training_test.count() #3197407\n",
    "training_train_int = training_train.map(lambda r: (int(r[0]), int(r[1]), float(r[2])))\n",
    "training_validation_int = training_validation.map(lambda r: (int(r[0]), int(r[1]), float(r[2])))\n",
    "training_test_int = training_test.map(lambda r: (int(r[0]), int(r[1]), float(r[2])))\n",
    "\n",
    "meanRating = training_train_int.union(training_validation_int).map(lambda x: x[2]).mean() #3.5261998976614137\n",
    "baselineRmse = sqrt(training_test_int.map(lambda x: (meanRating - x[2]) ** 2).reduce(add) / numTrTest)\n",
    "improvement = (baselineRmse - error) / baselineRmse * 100\n",
    "print \"The best model improves the baseline by %.2f\" % (improvement) + \"%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for later\n",
    "grouped = training_train_int.union(training_validation_int).groupBy(lambda r: r[1]).take(3)\n",
    "#grouped.map(lambda x: (list(x[1])))\n",
    "grouped.map(lambda x: avg(x[1])).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#for later \n",
    "meanRating = training_train_int.union(training_validation_int).map(lambda x: x[2]).mean()\n",
    "baselineRmse = sqrt(training_test_int.map(lambda x: (meanRating - x[2]) ** 2).reduce(add) / numTrTest)\n",
    "improvement = (baselineRmse - error) / baselineRmse * 100\n",
    "print \"The best model improves the baseline by %.2f\" % (improvement) + \"%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates_and_preds_tr.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "just_ratings = training.union(testing).map(lambda x: x[2])\n",
    "print just_ratings.count()\n",
    "just_ratings1 = just_ratings.map(lambda r: (float(r[0]))).take(19984024)\n",
    "meanRating = sc.parallelize(just_ratings1).mean() #3.397610611356352"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Make movie recommendations\n",
    "#load movies\n",
    "movies = sc.textFile(\"/mnt/mys3/movs.csv\")\n",
    "movies_header = movies.take(1)[0]\n",
    "movies.take(3)\n",
    "#ratings_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_data = movies.filter(lambda x: x!=movies_header).map(lambda x: x.split(\",\")).map(lambda tokens: (tokens[1],tokens[2])).cache()\n",
    "#movies_data.take(3)\n",
    "movies_data.count() # there are 18345 movies\n",
    "movies_titles = movies_data.map(lambda x: (int(x[0]),x[1]))\n",
    "movies_titles.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get specific number of movies\n",
    "ratings_data_int = ratings_data.map(lambda r: (int(r[0]), int(r[1]), float(r[2])))\n",
    "def get_counts_and_averages(ID_and_ratings_tuple):\n",
    "    nratings = len(ID_and_ratings_tuple[1])\n",
    "    #print ID_and_ratings_tuple[1]\n",
    "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
    "\n",
    "movie_ID_with_ratings = (ratings_data_int.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "movie_ID_with_avg_ratings = movie_ID_with_ratings.map(get_counts_and_averages)\n",
    "movie_rating_counts = movie_ID_with_avg_ratings.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_ID_with_ratings.map(get_counts_and_averages).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_rating_counts.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratings_data_int = ratings_data.map(lambda r: (int(r[0]), int(r[1]), float(r[2]))).take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(movie_ID_with_ratings.take(3)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movies_data.take(3000)\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add new user ratings\n",
    "new_user_ID = 0\n",
    "\n",
    "# The format of each line is (userID, movieID, rating)\n",
    "new_user_ratings = [\n",
    "     (0,10,8), # GoldenEye (1995)\n",
    "     (0,253,9), # Interview with the Vampire: The Vampire Chronicles (1994)\n",
    "     (0,296,4), # Pulp Fiction (1994)\n",
    "     (0,19,2), # Ace Ventura: When Nature Calls (1995)\n",
    "     (0,837,7), # Matilda (1996)\n",
    "     (0,355,3), # Flintstones, The (1994)\n",
    "     (0,2571,10), # Matrix, The (1999)\n",
    "     (0,329,6), # Star Trek: Generations (1994)\n",
    "     (0,858,5) , # Godfather, The (1972)\n",
    "     (0,912,4) # Casablanca (1942)\n",
    "    ]\n",
    "new_user_ratings_RDD = sc.parallelize(new_user_ratings) #make into RDD\n",
    "print 'New user ratings: %s' % new_user_ratings_RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#include new ratings in the ratings data RDD\n",
    "data_with_new_ratings = ratings_data.union(new_user_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train new model\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "new_ratings_model = ALS.train(data_with_new_ratings, best_rank, seed=seed, iterations=iterations, lambda_=reg_parameter)\n",
    "tt = time() - t0\n",
    "\n",
    "print \"New model trained in %s seconds\" % round(tt,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
    "new_user_unrated_movies = (movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "# Predict new ratings for all the movies using the input RDD, new_user_unrated_movies RDD, with new_ratings_model.predictAll() to \n",
    "new_user_recommendations = new_ratings_model.predictAll(new_user_unrated_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_user_recommendations.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform new_user_recommendations into pairs of the form (Movie ID, Predicted Rating)\n",
    "new_user_recommendations_rating = new_user_recommendations.map(lambda x: (x.product, x.rating))\n",
    "new_user_recommendations_rating_title_and_count = new_user_recommendations_rating.join(movies_titles).join(movie_rating_counts)\n",
    "new_user_recommendations_rating_title_and_count.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Confirm whether there are multiple movies named \"Matrix\", to check whether results include movies rated by new user\n",
    "movies_data.filter(lambda x: \"matrix\" in x[1].lower()).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Filter out movies that new user has reviewed from predictions list \n",
    "reviewed_movies = map(lambda x: x[1], new_user_ratings)\n",
    "# reviewed_movies # 10, 253, 296, 19, 837, 355, 2571, 329, 858, 912\n",
    "filtered_predictions = new_user_recommendations_rating_title_and_count.filter(lambda x:x[0] not in reviewed_movies) #18335\n",
    "#check against original list of predictions\n",
    "#filtered_predictions.count() # 18335\n",
    "#new_user_recommendations_rating_title_and_count.count() #18345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bring to format title, rating, number of reviews\n",
    "formatted_filtered_predictions = filtered_predictions.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "formatted_filtered_predictions.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#filter out movies with less than 25 ratings\n",
    "top_movies = formatted_filtered_predictions.filter(lambda r: r[2]>=25).takeOrdered(20, key=lambda x: -x[1])\n",
    "\n",
    "print ('TOP recommended movies (with more than 25 reviews):\\n%s' %'\\n'.join(map(str, top_movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get new rating for a particular movie, prviously unrated by the new user\n",
    "my_movie = sc.parallelize([(0, 1000)]) # Quiz Show (1994)\n",
    "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
    "individual_movie_rating_RDD.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
    "\n",
    "model_tr_path = os.path.join('..', 'models', 'movie_lens_als')\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, model_path)\n",
    "same_model = MatrixFactorizationModel.load(sc, model_tr_path)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "name": "test",
  "notebookId": 10
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
